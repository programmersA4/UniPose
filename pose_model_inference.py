# -*- coding: utf-8 -*-
"""pose_model_inference.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1VBxpjDnR54B-JhNn3D8iN3MbC6Te9cpF
"""

import sys
import numpy as np
import cv2
import math
import os, random
# import joblib

import torch.optim
import torch.nn as nn
import torch.backends.cudnn as cudnn
import torch.nn.functional as F
from model.unipose import unipose

from sklearn.externals import joblib


# Load pretrained unipose model
model = unipose(dataset='COCO', num_classes=16, backbone='resnet', output_stride=16, sync_bn=True, freeze_bn=False, stride=8)
checkpoint = torch.load('pretrained/UniPose_COCO.pth', map_location=torch.device('cpu'))
p = checkpoint 

state_dict = model.state_dict()
model_dict = {}

for k,v in p.items():
    if k in state_dict:
        model_dict[k] = v

state_dict.update(model_dict)
model.load_state_dict(state_dict)


# Get keypoints from maps
def get_kpts(maps, img_h = 368.0, img_w = 368.0):
    maps = maps.clone().cpu().data.numpy()
    map_6 = maps[0]

    kpts = []
    for m in map_6[1:]:
        h, w = np.unravel_index(m.argmax(), m.shape)
        x = int(w * img_w / m.shape[1])
        y = int(h * img_h / m.shape[0])
        kpts.append([x,y])
    return kpts


# Get keypoint coordinates from img
def unipose_write(img_path):
    center   = [184, 184]
    img  = np.array(cv2.resize(cv2.imread(img_path),(368,368)), dtype=np.float32)
    img  = img.transpose(2, 0, 1)
    img  = torch.from_numpy(img)
    mean = [128.0, 128.0, 128.0]
    std  = [256.0, 256.0, 256.0]
    for t, m, s in zip(img, mean, std):
        t.sub_(m).div_(s)

    img = torch.unsqueeze(img, 0)

    model.eval()

    input_var = img
    heat = model(input_var)
    heat = F.interpolate(heat, size=input_var.size()[2:], mode='bilinear', align_corners=True)

    kpts = get_kpts(heat, img_h=368.0, img_w=368.0)

    im = cv2.resize(cv2.imread(img_path),(368,368))
    for i, kpt in enumerate(kpts):
        x, y = kpt
        cv2.circle(im, (x, y), 5, (0, 255, 255), thickness=-1, lineType=cv2.FILLED)
        cv2.putText(im, str(i), (x, y), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 1, lineType=cv2.LINE_AA)
    
    return im, kpts


# Calculate degree by coordinates
def calculate_degree(point1, point2, point3):
    o1 = math.atan2((point1[1]-point2[1]),(point1[0]-point2[0]))
    o2 = math.atan2((point3[1]-point2[1]),(point3[0]-point2[0]))

    deg1=abs((o1-o2)*180/math.pi)
    deg2=360-deg1

    return min(deg1,deg2)


# Get a list of angles for each joint 
def angular_calculate(input_points):
    elbow_left_degree=calculate_degree(input_points[8],input_points[6],input_points[4]) # 6
    elbow_right_degree=calculate_degree(input_points[9],input_points[7],input_points[5]) # 7
    shoulder_left_degree=calculate_degree(input_points[6],input_points[4],input_points[10]) #4
    shoulder_right_degree=calculate_degree(input_points[7],input_points[5],input_points[11]) #5
    pelvis_left_degree=calculate_degree(input_points[4],input_points[10],input_points[12]) #10
    pelvis_right_degree=calculate_degree(input_points[5],input_points[11],input_points[13]) #11
    knee_left_degree=calculate_degree(input_points[10],input_points[12],input_points[14]) #12
    knee_right_degree=calculate_degree(input_points[11],input_points[13],input_points[15]) #13
    
    points_angular_list = [elbow_left_degree, elbow_right_degree, shoulder_left_degree, 
                          shoulder_right_degree, pelvis_left_degree, pelvis_right_degree,
                          knee_left_degree, knee_right_degree]
    
    return points_angular_list


def inference_model(class_name, test_img_path, model_dir='classifier'):
    # load classifier
    model_name = class_name + '_model.pkl'
    model_name = os.path.join(model_dir, model_name)
    classifier = joblib.load(model_name) 

    # load scaler
    scaler_name = class_name + '_scaler.pkl'
    scaler_name = os.path.join(model_dir, scaler_name)
    scaler = joblib.load(scaler_name) 

    X_test = []
    img, points=unipose_write(test_img_path)
    for i,j in points:
      X_test.append(i)
      X_test.append(j)
    X_test += angular_calculate(points)

    X_test = scaler.transform([X_test])
    pred = classifier.predict(X_test)

    return bool(pred)

# if __name__ == "__main__":
#     # inference_model('pushup', 'test.jpeg', model_dir='classifier')
#     print(inference_model('pushup', 'mil-tech-s.jpg', model_dir='classifier'))
